
<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Audio-Visual Scene Understanding</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Organizers" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="CVPR 2021 Tutorial" />
<meta property="og:description" content="CVPR 2021 Tutorial" />
<link rel="canonical" href="https://audio-visual-scene-understanding.github.io/" />
<meta property="og:url" content="https://audio-visual-scene-understanding.github.io/" />
<meta property="og:site_name" content="Audio-Visual Scene Understanding" />
<script type="application/ld+json">
{"description":"CVPR 2021 Tutorial","@type":"WebSite","url":"https://audio-visual-scene-understanding.github.io/","name":"Audio-Visual Scene Understanding","headline":"Audio-Visual Scene Understanding"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="/assets/css/style.css?v=6630701df1d052c81ea810d987f1f29fdd76c5ad">
    <link rel="stylesheet" href="/assets/mystyle.css">


  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Audio-Visual Scene Understanding</h1>
      <h2 class="project-tagline">CVPR 2021<br> Location: #<br>Time: # </h2>
      
      
    </section>

    <section class="main-content">
<!--       <h2 id="organizers">Organizers</h2>
 -->
<div class="container">
  <h2>Organizers</h2>
    <div>

      <div class="instructor">
      <a href="https://dtaoo.github.io/"  target="_blank">
      <div class="instructorphoto"><img src="https://i.postimg.cc/ncrfsmC7/dihu.jpg" width="20%" hspace="2%">   </div>  
      <div>Di Hu<br><small>Renmin University of China</small></div></a>

      </div>
  
      <div class="instructor">
              <a href="http://yapengtian.org/"  target="_blank">

      <div class="instructorphoto"><img src="https://i.postimg.cc/NFfqk9D3/yapeng.jpg" width="20%" hspace="2%">  </div> 
      <div>Yapeng Tian<br><small>University of Rochester</small></div></a>

      </div>

      <div class="instructor">
              <a href="https://www.cs.rochester.edu/u/lchen63/"  target="_blank">

      <div class="instructorphoto"><img src="https://i.postimg.cc/L5CdC90n/Lele.jpg" width="20%" hspace="2%"> </div>
      <div>Lele Chen<br><small>University of Rochester</small></div></a>

      </div>

      <div class="instructor">
              <a href="https://www.amir-zadeh.com/"  target="_blank">

      <div class="instructorphoto"><img src="https://i.postimg.cc/85bgvBRd/Amir.jpg" width="20%" hspace="2%"></div>
      <div>Amir Zadeh<br><small>Carnegie Mellon University</small></div></a>
      </div>

      <div class="instructor">
              <a href="http://www2.ece.rochester.edu/~zduan/"  target="_blank">

      <div class="instructorphoto"><img src="https://i.postimg.cc/764ybQ2Y/duan.jpg" width="20%" hspace="2%">     </div>
      <div>Zhiyao Duan<br><small>University of Rochester</small></div></a>
      </div>
  
      <div class="instructor">
              <a href="https://www.urmc.rochester.edu/labs/maddox.aspx"  target="_blank">

      <div class="instructorphoto"><img src="https://i.postimg.cc/HLXgYCjh/ross.jpg" width="20%" hspace="2%"></div>   
      <div>Ross K. Maddox<br><small>University of Rochester</small></div></a>

    </div>

    <div class="instructor">
      <a href="https://www.cs.rochester.edu/~cxu22/"  target="_blank">

    <div class="instructorphoto"><img src="https://i.postimg.cc/1RJZ5B5s/xu.jpg" width="20%" hspace="2%"></div>   
  <div>Chenliang Xu<br><small>University of Rochester</small></div></a>
    </div>





</div>


<div class="containertext">
  <h2 style="text-align: center">Overview</h2>
    <p>Sight and hearing are two of the most important senses for human perception. From cognitive per- spective, the visual and auditory information is actually slightly discrepant, but the percept is unified with multisensory integration. Whatâ€™s more, when there are multiple input senses, human reactions usually perform more exactly or efficiently than single sense. Inspired by this, for computational models, our community has begun to explore marrying computer vision with audition, and targets to address some essential problems of audio-visual learning then further develops them into interesting and worthwhile tasks. In recent years, we were delighted to witness many developments in learning from both visual and auditory data.
    </p>
    <p>This tutorial aims to cover recent advances in audio-visual learning, from the neuroscience study of humans to the computation models of machine. For each research sub-topic, we will give a concrete introduction of the contained problems/tasks, and the current research progress as well as the open problems. We hope the audience, not only the graduate students but also the researchers new in this area, can benefit from this tutorial and learn the principle problems and cutting-edge approaches of audio-visual learning.
    </p>
    </p>
</div> 

<br>


<div class="container">
  <h2>Schedule</h2>
    <div class="schedule">
      
    </div>
</div>




<br>



<!--
<h2 id="time-and-location">Time and Location</h2>
<p>June 17, 2019. 9:00 am - 12:30 pm. Room 203A</p>

<h2 id="tutorial-schedule">Tutorial Schedule</h2>

<ul>
  <li>9:00 am - 9:10 am : Introduction (Nikhil Naik)</li>
  <li>9:10 am - 9:55 am : Few-shot meta-learning (Chelsea Finn)</li>
  <li>9:55 am - 10:40 am : Multi-task learning and meta-learning (Nitish Keskar)</li>
  <li>10:40 am - 11:00 am : Coffee Break</li>
  <li>11:00 am - 11:45 am: Neural Architecture Search (Nikhil Naik)</li>
  <li>11:45 am - 12:30 am: Bayesian Optimization and Meta-learning (Frank Hutter)</li>
</ul>


      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

  -->
  </body>
</html>
